##<center>第一次论文阅读</center>

​		由于本身专业的原因，对于机器学习方面的关注更多，对于数字信号处理和密码学相关方面还有欠缺，只阅读了后三篇文章“2019-X-DeepSCA Cross-Device Deep Learning Side Channel Attack”（[代码](https://github.com/SparcLab/X-DeepSCA))、“2021-Remote Power Attacks on the Versatile Tensor Accelerator in Multi-Tenant FPGAs”和“2021-Remote Power Side-Channel Attacks on BNN Accelerators in FPGAs”。**这次论文阅读报告主要是对于“2021-Remote Power Attacks on the Versatile Tensor Accelerator in Multi-Tenant FPGAs”论文的idea以及其意义的展示**。

### idea：

##### 现实可行性：

​		在目前云计算火热的环境下，硬件虚拟化的实现以及商业情况的驱使下，部署模型在远程租用的服务器上，并且一台机器上有多个租户是非常普遍的现象，这些现实情况共同导致了文章提出的攻击方式能够进行。

##### 技术可行性：

​		对于神经网络来说最重要的是网络的参数，其次是网络的架构以及一些运算结构。文章通过矩阵乘法的GEMM指令重构层内模型的架构和卷积核的大小等信息来逆向获得神经网络的架构。因为网络推理过程中架构和参数是被冻结的，所以当一个租户在一台服务器上部署了训练好的模型后，进行推理的整个过程都是侧信道泄露参数信息的过程。文章假设同一租户是共用底层电源配置的，从而能够实施电源功耗分析。

​		文章将注意力集中在编译命令上，非常像逆向的过程，只不过这次是通过运行过程中泄露的侧信道信息逆向AI指令集合。文章首先构建了一个基于电源电压降曲线进行指令匹配的模型，这一步文章没有详细说明，但是理论上攻击者是租户可以将所有指令都在机器上运行来获得模式匹配的数据，考虑延时等再运用时间对应，即可获得。随后根据GEMM指令的功耗曲线再进一步分析获得矩阵维度信息，从而逆向出神经网络层中的输入/输出/batch_size等信息，从而获得该层的架构。再根据逆向出来的维度信息以及“对于卷积层计算工作负载，在ALU计算之前，首先将输入数据输入到GEMM指令中”的规律，识别卷积层数。随后通过更长尺度的功耗信息，匹配模型的种类。从而获得模型的整体架构。

##### 评价：

​		一开始以为是逆向整个神经网络，还很好奇，但是最后却有点失望。站在AI专业来看，首先就是逆向的神经网络种类局限在自己已知大致结构并且都是比较简单，属于不需要耗费什么资源就能够自主搭建的卷积神经网络。这种网络更关键的不是架构怎样，而是其针对对象以及参数，针对不同的输入同一模型架构可以复用但在这种小模型上参数几乎是没法复用的，获得模型架构之后更长的时间是在调整超参数以及训练策略上，甚至是训练数据上。其次其通过GEMM指令逆向层结构的过程一笔带过，很让人怀疑做出来没有，因为GEMM指令只是矩阵的批乘法，基于其获得输入输出维度是可以理解的，但是几乎所有情况中一层卷积层都会包括：卷积、池化、全连接和激活等基本操作，VTA中池化等操作都是张量ALU单元来做，不仅仅是给出图片的ALU-add操作，也就是说ALU单元也会变更输入输出维度，并且其中的维度信息很多时候也是神经网络结构重要的一部分。

### meanings：

##### 场景意义：

​		与2019年论文关注于使用神经网络进行多设备的泛化侧信道攻击不同，2021年的两篇文章则将场景假设在一块远程共同租用的FPGA上。这个场景的限制更具备现实意义，按照19年论文的结论，设备间的差异在绝大部分时候比密码本身的差异更大，但是使用简单的多层全连接网络就能实现不同型号数据来源的功耗曲线的分析，这其实表明了放大模型参数、数据来源型号以及数据数量从而获得一个出色的密码破译神经网络是有潜力的，在目前大模型的背景下微调预训练的模型来使其在给定FPGA上有更出色表现可能是进一步的工作方向，这也是安全需要注意的。但是，这样的攻击方式显著的增加了攻击成本（需要多个被攻击装置的同型号装置），这也是机器学习泛化性的前提，不然机器学习会学习到拟合当前装置的参数。当然如果出现了超泛化的大模型，以及相关微调工作，那么这个攻击方式是很可怕的，因为其将打破侧信道攻击中victim设备需要完全占有并任意操作的限制。同样抱有这个目的的2021年这两篇基于远程设备的攻击可能是目前最最现实的场景。通过获得远程设备的侧信道信息，逆向同设备用户的神经网络信息。在目前这样云计算、远程模型部署的环境下是非常值得警惕的。但是两篇文章的逆向工作都存在一定问题，基于VTA攻击的文章在上述评价中已经给出，逆向BNN网络的文章的主要问题在于假设太强了，其逆向过程仅能区分前景以及背景，在其假设的输入定义下也就是区分像素是0还是1，这也是BNN网络的缺点之一。

​		总的来看，“2021-Remote Power Attacks on the Versatile Tensor Accelerator in Multi-Tenant FPGAs”论文给出的攻击场景是较为贴近实际的。

##### 研究方向意义：

​		其将逆向过程与代码结合起来，利用代码中的特征，逆向神经网络特征是一个很好的想法。我认为和从前DPA，CPA出现的时候一样，根据代码的特征对应功耗曲线的特征，从而定位，并进行更细致的统计分析这一思想一脉相承。但是在AI运用下，很多传统方式无法获得的特征都能够通过神经网络来获取，所以无论是代码的模式匹配，还是模式与需要逆向的特征匹配，都可以和神经网络结合，19年的文章也表明了在功耗曲线的特征提取中使用神经网络分类是可行的。

​		总而言之，对应运行代码的特征来分析逆向神经网络是一种很有意义的方向，并且加上神经网络特征提取和分类工作，在功耗分析对应过程中会有更重大的意义。

### 论文写作上：

​		基本的结构较为常见：摘要，背景和本文贡献介绍，技术介绍，模型介绍，实验分析以及数据图标，相关工作和总结。比较意外的是相关工作写在了最后，其中提到了给出的21年另外一篇文章，也就是这次的第四篇。使用的都是TDC电源功耗分析，都是远程多租户FPGA攻击，可能是为了减少自己的自引，这两篇文章的一二作换了个位。而且文章并没有未来工作等讨论部分。一些图片的引用存在名称和小细节上的问题。并且全文几乎没有出现技术相关的公式等描述自己的工作。比较四五两篇文章的质量，我觉得第四篇稍高于第五篇，但都缺少技术细节，并且没有相关代码找到。查看了相关会议，第四篇发表在B类的DATE上，第五篇发表在C类的FCCM上。相比之下，第三篇虽然应用的DNN虽然很简单，但是光就写作和实验的完整而言，都比45好很多，其展示了DNN相关参数的训练过程及结果，深挖了在测试板上跟踪数的影响并给出了混合N-trace的方法，不仅从准确率方面证明了其模型的性能，还从信噪比等所需数据量上证明了DNN模型相比于传统CPA的优越性，查看其发在A类的DAC上。